{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "56c08bf1bf97484a8c3e6fce58680db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae64645993354b44b05af0ba50221ca3",
              "IPY_MODEL_14f2cf27d55d46e7ae8f0975d6f91542",
              "IPY_MODEL_098586c04a8447c0b47235099ec0271f"
            ],
            "layout": "IPY_MODEL_f00c11efa2244aeda31671a4e09920e0"
          }
        },
        "ae64645993354b44b05af0ba50221ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9963818ae10f486c90cedc06eb926b8b",
            "placeholder": "​",
            "style": "IPY_MODEL_cf73f72be61f4aba95203197cea9f356",
            "value": "  4%"
          }
        },
        "14f2cf27d55d46e7ae8f0975d6f91542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b935ed7e118848cfb3c0e0e552ba1ac3",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad780b79e15547068ef365b8d3a4703f",
            "value": 408
          }
        },
        "098586c04a8447c0b47235099ec0271f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9dabce848bc4bb4937e545302e2cd96",
            "placeholder": "​",
            "style": "IPY_MODEL_ccbaaaae69884d12a3e02eadb91c2d2b",
            "value": " 408/10000 [00:36&lt;13:21, 11.97it/s]"
          }
        },
        "f00c11efa2244aeda31671a4e09920e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9963818ae10f486c90cedc06eb926b8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf73f72be61f4aba95203197cea9f356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b935ed7e118848cfb3c0e0e552ba1ac3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad780b79e15547068ef365b8d3a4703f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": "red",
            "description_width": ""
          }
        },
        "c9dabce848bc4bb4937e545302e2cd96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccbaaaae69884d12a3e02eadb91c2d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abpkUTnUpQmr",
        "outputId": "b061a672-610d-4f6b-d0c3-60000dd0c3fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CW-Toy' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from typing import List, Tuple\n",
        "from tqdm.notebook import tqdm\n",
        "from scipy import signal\n",
        "import librosa\n",
        "import numpy as np\n",
        "import torch\n",
        "import scipy\n",
        "from functools import reduce\n",
        "\n",
        "import torchaudio\n",
        "import torch\n",
        "import numpy as np\n",
        "from IPython.display import Audio\n",
        "\n",
        "\n",
        "!git clone https://github.com/alem1r/CW-Toy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CW(object):\n",
        "\n",
        "    def __init__(self, model, device, labels: List[str]):\n",
        "        '''\n",
        "        Creates an instance of the class.\n",
        "\n",
        "        INPUT ARGUMENTS:\n",
        "\n",
        "        model  : The model on which the attack is supposed to be performed.\n",
        "        device : Either 'cpu' if we have only CPU or 'cuda' if we have GPU\n",
        "        labels : Label/Dictionary of the model.\n",
        "        '''\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.labels = labels\n",
        "\n",
        "    def _encode_transcription(self, transcription: List[str]) -> List[str]:\n",
        "        '''\n",
        "        Convert/Encode a string transcription into a tensor of numerical encodings based on a predefined dictionary.\n",
        "        '''\n",
        "        # Define the dictionary\n",
        "        dictionary = {'-': 0, '|': 1, 'E': 2, 'T': 3, 'A': 4,\n",
        "                      'O': 5, 'N': 6, 'I': 7, 'H': 8, 'S': 9,\n",
        "                      'R': 10, 'D': 11, 'L': 12, 'U': 13, 'M': 14,\n",
        "                      'W': 15, 'C': 16, 'F': 17, 'G': 18, 'Y': 19,\n",
        "                      'P': 20, 'B': 21, 'V': 22, 'K': 23, \"'\": 24,\n",
        "                      'X': 25, 'J': 26, 'Q': 27, 'Z': 28} #wav2vec uses this dictionary\n",
        "\n",
        "        # Convert transcription string to list of characters\n",
        "        chars = list(transcription)\n",
        "\n",
        "        # Encode each character using the dictionary\n",
        "        encoded_chars = [dictionary[char] for char in chars]\n",
        "\n",
        "        # Concatenate the encoded characters to form the final encoded transcription\n",
        "        encoded_transcription = torch.tensor(encoded_chars)\n",
        "\n",
        "        # Returning the encoded transcription\n",
        "        return encoded_transcription\n",
        "\n",
        "    def CW_ATTACK(self, input__: torch.Tensor, target: List[str] = None,\n",
        "           epsilon: float = 0.3, c: float = 1e-4, learning_rate: float = 0.01,\n",
        "           num_iter: int = 1000, decrease_factor_eps: float = 1,\n",
        "           num_iter_decrease_eps: int = 10, optimizer: str = None\n",
        "           ) -> np.ndarray:\n",
        "\n",
        "        '''\n",
        "        Implements the Carlini and Wagner attack for adversarial examples on a speech recognition model.\n",
        "        The CW attack aims to find a small perturbation to the input that causes a model to misclassify the input.\n",
        "        Paper: https://arxiv.org/pdf/1801.01944.pdf\n",
        "\n",
        "        INPUT ARGUMENTS:\n",
        "\n",
        "        input__       : Input audio. Ex: Tensor[0.1,0.3,...] or (samples,)\n",
        "                        Type: torch.Tensor\n",
        "\n",
        "        target        : Target transcription (needed if the you want targeted\n",
        "                        attack) Ex: [\"my name is mango.\"].\n",
        "                        Type: List[str]\n",
        "                        CAUTION:\n",
        "                        Please make sure these characters are also present in the\n",
        "                        dictionary of the model also.\n",
        "\n",
        "        epsilon       : Noise controlling parameter.\n",
        "                        Type: float\n",
        "\n",
        "        c             : Regularization term controlling factor.\n",
        "                        Type: float\n",
        "\n",
        "        learning_rate : learning_rate of optimizer.\n",
        "                        Type: float\n",
        "\n",
        "        num_iter      : Number of iteration of attack.\n",
        "                        Type: int\n",
        "\n",
        "        decrease_factor_eps   : Factor to decrease epsilon during search\n",
        "                                Type: float\n",
        "\n",
        "        num_iter_decrease_eps : Number of iterations after which to decrease epsilon\n",
        "                                Type: int\n",
        "\n",
        "        optimizer     : Name of the optimizer to use for the attack.\n",
        "                        Type: str\n",
        "\n",
        "\n",
        "\n",
        "        RETURNS:\n",
        "\n",
        "        np.ndarray : Perturbed audio\n",
        "        '''\n",
        "\n",
        "\n",
        "        if epsilon <= 0:\n",
        "            raise Exception(\"Value of epsilon should be greater than 0\")\n",
        "\n",
        "        # Convert the input audio to a PyTorch tensor\n",
        "        input_audio = input__.clone().to(self.device).float()\n",
        "\n",
        "        # Making audio differentiable\n",
        "        input_audio.requires_grad_()\n",
        "\n",
        "        # Cloning the original audio\n",
        "        input_audio_orig = input_audio.clone().to(self.device)\n",
        "\n",
        "        # Define the optimizer\n",
        "        if optimizer == \"Adam\":\n",
        "\n",
        "            optimizer = torch.optim.Adam([input_audio], lr=learning_rate)\n",
        "\n",
        "        else:\n",
        "\n",
        "            optimizer = torch.optim.SGD([input_audio], lr=learning_rate)\n",
        "\n",
        "        # Setting our inital parameters\n",
        "        successful_attack = False\n",
        "        num_successful_attacks = 0\n",
        "\n",
        "\n",
        "        # Encode the target transcription\n",
        "        encoded_transcription = self._encode_transcription(target)\n",
        "\n",
        "        # Convert the target transcription to a PyTorch tensor\n",
        "        target_tensor = torch.from_numpy(np.array(encoded_transcription)).to(self.device).long()\n",
        "\n",
        "        for i in tqdm(range(num_iter), colour=\"red\"):\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Compute the model’s prediction\n",
        "            output, _ = self.model(input_audio)\n",
        "\n",
        "            # Softmax Activation for computing logits\n",
        "            output = F.log_softmax(output, dim=-1)\n",
        "\n",
        "            # Compute the CTC loss function between the model's output and the target transcription.\n",
        "            output_length = torch.tensor([output.shape[1]], dtype=torch.long).to(self.device)\n",
        "            output = output.transpose(0, 1)\n",
        "            target_length = torch.tensor([len(encoded_transcription)], dtype=torch.long).to(self.device)\n",
        "            loss_classifier = F.ctc_loss(output, target_tensor, output_length, target_length, blank=0, reduction='mean')\n",
        "\n",
        "            # Regularization term to minimize the perturbation\n",
        "            loss_norm = torch.norm(input_audio - input_audio_orig)\n",
        "\n",
        "            # Combine the losses and compute gradients\n",
        "            loss = (c * loss_norm) + ( loss_classifier)\n",
        "\n",
        "            # Computing gradients of our input w.r.t loss\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the input audio with gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculating perturbation by subtracting the optimized audio from cloned one\n",
        "            perturbation = input_audio - input_audio_orig\n",
        "\n",
        "            # Project the perturbation onto the epsilon ball in range (-eps, eps)\n",
        "            perturbation = torch.clamp(perturbation, -epsilon, epsilon)\n",
        "\n",
        "            # Cliping to audio in range (-1, 1)\n",
        "            input_audio.data = torch.clamp(input_audio_orig + perturbation, -1, 1)\n",
        "\n",
        "            # Storing model's current inference and target transcription in new variables for computing WER\n",
        "            string1 = list(filter(lambda x: x!= '',self.INFER(input_audio).split(\"|\")))\n",
        "            string2 = list(reduce(lambda x,y: x+y, target).split(\"|\"))\n",
        "\n",
        "\n",
        "                    # Computing WER while also making sure length of both strings is same\n",
        "                    # This will also early stop the attack if we reach our target transcription (WER=0)\n",
        "\n",
        "\n",
        "            if len(string1) == len(string2):\n",
        "                if self._wer(string1, string2)[0] == 0:\n",
        "                    print(\"Breaking for loop because targeted Attack is performed successfully !\")\n",
        "                    adv_example = input_audio\n",
        "                    return adv_example.detach().cpu().numpy()\n",
        "\n",
        "            elif len(string1) > len(string2):\n",
        "                diff = len(string1) - len(string2)\n",
        "                for i in range(diff):\n",
        "                    string2.append(\"<eps>\")\n",
        "                if self._wer(string1, string2)[0] == 0:\n",
        "                    print(\"Breaking for loop because targeted Attack is performed successfully !\")\n",
        "                    adv_example = input_audio\n",
        "                    return adv_example.detach().cpu().numpy()\n",
        "\n",
        "            else:\n",
        "                diff = len(string2) - len(string1)\n",
        "                for i in range(diff):\n",
        "                    string1.append(\"<eps>\")\n",
        "                if self._wer(string1, string2)[0] == 0:\n",
        "                    print(\"Breaking for loop because targeted Attack is performed successfully !\")\n",
        "                    adv_example = input_audio\n",
        "                    return adv_example.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "        adv_example = input_audio\n",
        "        return adv_example.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "    def _wer(self, reference, prediction) -> Tuple[int, Tuple[int, int, int]]:\n",
        "\n",
        "        '''\n",
        "\n",
        "        This function compares each element in the prediction and reference sequences and counts the number of correct, substitution, insertion, and deletion errors.\n",
        "        It then calculates the Word Error Rate based on these counts and returns the WER along with the counts for substitution, insertion, and deletion errors.\n",
        "\n",
        "        If transcriptions are not equal, make them equal by appending <eps> in which ever transcription who's length is smaller than the other.\n",
        "\n",
        "        RETURNS:\n",
        "\n",
        "        Tuple[int, Tuple[int, int, int]] : single transcription's WER along with another tuple containing information of (Substitution, Insertion, Deletion)\n",
        "        '''\n",
        "\n",
        "        correct = 0\n",
        "        substitution = 0\n",
        "        insertion = 0\n",
        "        deletion = 0\n",
        "        #loop through sequences\n",
        "        for i in range(len(reference)):\n",
        "            #if they match, increments correct\n",
        "            if prediction[i] == reference[i]:\n",
        "                correct +=1\n",
        "            #if they don't match and neither is an eps token, increments substitution\n",
        "            elif prediction[i] != reference[i] and prediction[i] != '<eps>' and reference[i] != '<eps>':\n",
        "                substitution+=1\n",
        "            elif prediction[i] == '<eps>':\n",
        "                deletion+=1\n",
        "            elif prediction[i] != reference[i] and reference[i] == '<eps>':\n",
        "                insertion+=1\n",
        "        wer = (substitution + insertion + deletion) / (correct + substitution + deletion + insertion)\n",
        "        print(wer)\n",
        "        return wer, (substitution, insertion, deletion)\n",
        "\n",
        "\n",
        "    def INFER(self, input_: torch.Tensor) -> str:\n",
        "\n",
        "        '''\n",
        "        Method for performing inference by the model.\n",
        "        It takes an input tensor, performs inference using a model, decodes the model's output sequence, and returns the decoded string.\n",
        "\n",
        "        '''\n",
        "\n",
        "        # Inference method of the model\n",
        "        blank = 0\n",
        "        output, _ = self.model(input_.to(self.device))\n",
        "        #argmax along the last dimension of the first element of model's output\n",
        "        encodedTrans = torch.argmax(output[0], axis=-1)\n",
        "        #remove consecutive duplicate indices.\n",
        "        encodedTrans = torch.unique_consecutive(encodedTrans, dim=-1)\n",
        "        indices = [i for i in encodedTrans if i != blank]\n",
        "        return \"\".join([self.labels[i] for i in indices])\n"
      ],
      "metadata": {
        "id": "pi5uNbbophcT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
        "model = bundle.get_model()"
      ],
      "metadata": {
        "id": "ZaJTT39-qmmq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the device available during the current environment (CUDA is recommended!)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T13:52:51.528398Z",
          "iopub.execute_input": "2023-04-17T13:52:51.528817Z",
          "iopub.status.idle": "2023-04-17T13:52:54.196395Z",
          "shell.execute_reply.started": "2023-04-17T13:52:51.528777Z",
          "shell.execute_reply": "2023-04-17T13:52:54.195369Z"
        },
        "trusted": true,
        "id": "nogI7lcam6ft"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the audio\n",
        "input_audio, sample_rate = torchaudio.load('/content/CW-Toy/audio.wav')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T13:52:54.197974Z",
          "iopub.execute_input": "2023-04-17T13:52:54.198388Z",
          "iopub.status.idle": "2023-04-17T13:52:54.210116Z",
          "shell.execute_reply.started": "2023-04-17T13:52:54.198345Z",
          "shell.execute_reply": "2023-04-17T13:52:54.209134Z"
        },
        "trusted": true,
        "id": "HZ5cAC7Vm6fv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# My target\n",
        "target_transcription = 'THE CHILD ATE THE DOG'\n",
        "true_transcription = 'THE CHILD ALMOST HURT THE SMALL DOG'\n",
        "attack = CW(model, device, bundle.get_labels())\n",
        "target = list(target_transcription.upper().replace(\" \", \"|\"))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T13:52:54.211604Z",
          "iopub.execute_input": "2023-04-17T13:52:54.212050Z",
          "iopub.status.idle": "2023-04-17T13:52:54.218253Z",
          "shell.execute_reply.started": "2023-04-17T13:52:54.212001Z",
          "shell.execute_reply": "2023-04-17T13:52:54.217094Z"
        },
        "trusted": true,
        "id": "oqLN80CEm6fw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Carling-Wagner TARGETED**"
      ],
      "metadata": {
        "id": "kxu9yQ6Wm6gd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CW\n",
        "target_transc = attack.CW_ATTACK(input_audio, target, epsilon = 0.0015, c = 10,\n",
        "                  learning_rate = 0.00001, num_iter = 10000, decrease_factor_eps = 1,\n",
        "                  num_iter_decrease_eps = 10, optimizer = \"Adam\")\n",
        "\n",
        "#CW PRINT\n",
        "print('\\n',attack.INFER(torch.from_numpy(target_transc)).replace(\"|\",\" \"))\n",
        "#print(target_transcription)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T13:53:58.271233Z",
          "iopub.execute_input": "2023-04-17T13:53:58.271812Z",
          "iopub.status.idle": "2023-04-17T13:56:24.695118Z",
          "shell.execute_reply.started": "2023-04-17T13:53:58.271777Z",
          "shell.execute_reply": "2023-04-17T13:56:24.693936Z"
        },
        "trusted": true,
        "id": "g4YPu_Xqm6ge",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "56c08bf1bf97484a8c3e6fce58680db6",
            "ae64645993354b44b05af0ba50221ca3",
            "14f2cf27d55d46e7ae8f0975d6f91542",
            "098586c04a8447c0b47235099ec0271f",
            "f00c11efa2244aeda31671a4e09920e0",
            "9963818ae10f486c90cedc06eb926b8b",
            "cf73f72be61f4aba95203197cea9f356",
            "b935ed7e118848cfb3c0e0e552ba1ac3",
            "ad780b79e15547068ef365b8d3a4703f",
            "c9dabce848bc4bb4937e545302e2cd96",
            "ccbaaaae69884d12a3e02eadb91c2d2b"
          ]
        },
        "outputId": "8f03300e-9d44-43df-f70f-f9885217aa9c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56c08bf1bf97484a8c3e6fce58680db6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.5\n",
            "0.7142857142857143\n",
            "0.7142857142857143\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.5\n",
            "0.4\n",
            "0.5\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.4\n",
            "0.2\n",
            "0.2\n",
            "0.2\n",
            "0.2\n",
            "0.2\n",
            "0.2\n",
            "0.4\n",
            "0.4\n",
            "0.2\n",
            "0.4\n",
            "0.2\n",
            "0.2\n",
            "0.2\n",
            "0.2\n",
            "0.4\n",
            "0.2\n",
            "0.2\n",
            "0.2\n",
            "0.2\n",
            "0.4\n",
            "0.4\n",
            "0.2\n",
            "0.2\n",
            "0.2\n",
            "0.2\n",
            "0.4\n",
            "0.2\n",
            "0.2\n",
            "0.0\n",
            "Breaking for loop because targeted Attack is performed successfully !\n",
            "\n",
            " THE CHILD ATE THE DOG\n"
          ]
        }
      ]
    }
  ]
}